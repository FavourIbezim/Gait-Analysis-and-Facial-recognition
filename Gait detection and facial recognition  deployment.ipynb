{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load trained model\n",
    "with open('body_language_rf.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhance video quality for detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image(image):\n",
    "    \"\"\"Enhances a single image using the provided processing steps.\"\"\"\n",
    "    # Resize image to 640x640 pixels\n",
    "    #image = cv2.resize(image, (640, 640))\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    blurred_color = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Apply Unsharp Masking\n",
    "    gaussian_blurred_color = cv2.GaussianBlur(blurred_color, (9, 9), 10.0)\n",
    "    unsharp_color = cv2.addWeighted(blurred_color, 1.5, gaussian_blurred_color, -0.5, 0)\n",
    "\n",
    "    # Apply Laplacian sharpening to the grayscale version, then combine with color\n",
    "    laplacian_color = cv2.Laplacian(cv2.cvtColor(unsharp_color, cv2.COLOR_BGR2GRAY), cv2.CV_64F)\n",
    "    laplacian_color = cv2.convertScaleAbs(laplacian_color)\n",
    "    laplacian_color_bgr = cv2.cvtColor(laplacian_color, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Combine the unsharp and Laplacian sharpened images\n",
    "    final_color_sharpened = cv2.addWeighted(unsharp_color, 0.7, laplacian_color_bgr, 0.3, 0)\n",
    "\n",
    "    # Apply CLAHE to each channel separately\n",
    "    lab_image = cv2.cvtColor(final_color_sharpened, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l = clahe.apply(l)\n",
    "    enhanced_lab_image = cv2.merge((l, a, b))\n",
    "    enhanced_color_image = cv2.cvtColor(enhanced_lab_image, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return enhanced_color_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for detection of persons using Gait and facial recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "landmark_visibility_threshold = 0.8\n",
    "conf_thresh=0.5\n",
    "conf_thresh2=0.5\n",
    "\n",
    "# Load the YOLO model\n",
    "model_1 = YOLO(\"C:\\\\Users\\\\FAVOUR\\\\Downloads\\\\best(2).pt\")  # Replace with trained yolo model\n",
    "classes=['Teo','Ama','John','-','-'] #Input classes as in ymal file during training using format\n",
    "\n",
    "# Frame skipping parameter\n",
    "frame_skip = 5\n",
    "frame_count = 0\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Skip frames\n",
    "        frame_count+=1000\n",
    "        #frame_skip+=4\n",
    "        if frame_count % frame_skip != 0:\n",
    "            continue\n",
    "        # Recolor Feed\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img.flags.writeable = False \n",
    "        image = enhance_image(img)   \n",
    "\n",
    "        # Run inference on the frame\n",
    "        results_1 = model_1(image)  \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)        \n",
    "        id= str(results.pose_landmarks)        \n",
    "        no_of_people= len(list((results_1[0].boxes.cls)))\n",
    "        print(\"the number of people is:\", {no_of_people})\n",
    "                \n",
    "\n",
    "        if not id == \"None\":            \n",
    "            #Recolor image back to BGR for rendering\n",
    "            image.flags.writeable = True   \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            #Index for right body part\n",
    "            right_elbow_index = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "            right_shoulder_index = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "            right_hip_index = mp_pose.PoseLandmark.RIGHT_HIP\n",
    "            right_wrist_index = mp_pose.PoseLandmark.RIGHT_WRIST\n",
    "            right_heel_index = mp_pose.PoseLandmark.RIGHT_HEEL\n",
    "            right_knee_index = mp_pose.PoseLandmark.RIGHT_KNEE\n",
    "            right_ankle_index = mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "            \n",
    "            #Index for left body part\n",
    "            left_elbow_index = mp_pose.PoseLandmark.LEFT_ELBOW\n",
    "            left_shoulder_index = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "            left_hip_index = mp_pose.PoseLandmark.LEFT_HIP\n",
    "            left_wrist_index = mp_pose.PoseLandmark.LEFT_WRIST\n",
    "            left_heel_index = mp_pose.PoseLandmark.LEFT_HEEL\n",
    "            left_knee_index = mp_pose.PoseLandmark.LEFT_KNEE\n",
    "            left_ankle_index = mp_pose.PoseLandmark.LEFT_ANKLE\n",
    "            # Get the x and y coordinates of the left body part\n",
    "            left_elbow_cord= (int(results.pose_landmarks.landmark[left_elbow_index].x * image.shape[1]), int(results.pose_landmarks.landmark[left_elbow_index].y * image.shape[0]), 0)\n",
    "            left_shoulder_cord= (int(results.pose_landmarks.landmark[left_shoulder_index].x * image.shape[1]), int(results.pose_landmarks.landmark[left_shoulder_index].y * image.shape[0]),0)\n",
    "            left_hip_cord= (int(results.pose_landmarks.landmark[left_hip_index].x * image.shape[1]), int(results.pose_landmarks.landmark[left_hip_index].y * image.shape[0]),0)\n",
    "            left_wrist_cord= (int(results.pose_landmarks.landmark[left_wrist_index].x * image.shape[1]), int(results.pose_landmarks.landmark[left_wrist_index].y * image.shape[0]),0)\n",
    "            left_heel_cord= (int(results.pose_landmarks.landmark[left_heel_index].x * image.shape[1]), int(results.pose_landmarks.landmark[left_heel_index].y * image.shape[0]),0)\n",
    "            left_knee_cord= (int(results.pose_landmarks.landmark[left_knee_index].x * image.shape[1]), int(results.pose_landmarks.landmark[left_knee_index].y * image.shape[0]),0)\n",
    "            left_ankle_cord= (int(results.pose_landmarks.landmark[left_ankle_index].x * image.shape[1]), int(results.pose_landmarks.landmark[left_ankle_index].y * image.shape[0]),0)\n",
    "            left_hand_cord= (int(results.pose_landmarks.landmark[15].x * image.shape[1]), int(results.pose_landmarks.landmark[15].y * image.shape[0]),0)\n",
    "            #Get the x and y coordinates of the right body part\n",
    "            right_elbow_cord= (int(results.pose_landmarks.landmark[right_elbow_index].x * image.shape[1]), int(results.pose_landmarks.landmark[right_elbow_index].y * image.shape[0]), 0)\n",
    "            right_shoulder_cord= (int(results.pose_landmarks.landmark[right_shoulder_index].x * image.shape[1]), int(results.pose_landmarks.landmark[right_shoulder_index].y * image.shape[0]),0)\n",
    "            right_hip_cord= (int(results.pose_landmarks.landmark[right_hip_index].x * image.shape[1]), int(results.pose_landmarks.landmark[right_hip_index].y * image.shape[0]),0)\n",
    "            right_wrist_cord= (int(results.pose_landmarks.landmark[right_wrist_index].x * image.shape[1]), int(results.pose_landmarks.landmark[right_wrist_index].y * image.shape[0]),0)\n",
    "            right_heel_cord= (int(results.pose_landmarks.landmark[right_heel_index].x * image.shape[1]), int(results.pose_landmarks.landmark[right_heel_index].y * image.shape[0]),0)\n",
    "            right_knee_cord= (int(results.pose_landmarks.landmark[right_knee_index].x * image.shape[1]), int(results.pose_landmarks.landmark[right_knee_index].y * image.shape[0]),0)\n",
    "            right_ankle_cord= (int(results.pose_landmarks.landmark[right_ankle_index].x * image.shape[1]), int(results.pose_landmarks.landmark[left_ankle_index].y * image.shape[0]),0)\n",
    "            right_hand_cord= (int(results.pose_landmarks.landmark[16].x * image.shape[1]), int(results.pose_landmarks.landmark[16].y * image.shape[0]),0)\n",
    "            #Calculate the angles \n",
    "            right_arm_angle2 = calculateAngle(right_shoulder_cord, right_elbow_cord, right_hip_cord)\n",
    "            left_arm_angle2= calculateAngle(left_shoulder_cord, left_elbow_cord, left_hip_cord)\n",
    "            right_arm_angle1=calculateAngle(right_shoulder_cord, right_elbow_cord, right_wrist_cord)\n",
    "            left_arm_angle1=calculateAngle(left_shoulder_cord, left_elbow_cord, left_wrist_cord)\n",
    "            right_leg_angle1 =calculateAngle(right_shoulder_cord, right_hip_cord, right_knee_cord)\n",
    "            left_leg_angle1 =calculateAngle(left_shoulder_cord, left_hip_cord, left_knee_cord)\n",
    "            right_leg_angle2 =calculateAngle(right_hip_cord, right_knee_cord, right_ankle_cord)\n",
    "            left_leg_angle2 =calculateAngle(left_hip_cord, left_knee_cord, left_ankle_cord)\n",
    "\n",
    "            #distance between the heels\n",
    "            heel_dist = distance_between_landmarks(right_heel_cord, left_heel_cord)\n",
    "                                                \n",
    "            #distance between the wrists\n",
    "            wrist_dist= distance_between_landmarks(right_wrist_cord, left_wrist_cord)\n",
    "        \n",
    "            #distance between the knee\n",
    "            knee_dist= distance_between_landmarks(right_knee_cord, left_knee_cord)\n",
    "            #height\n",
    "            height= distance_between_landmarks(right_elbow_cord,right_heel_cord)\n",
    "            #reference point\n",
    "            center =  calculate_square_center(right_elbow_cord,left_elbow_cord,right_hip_cord,left_hip_cord)  \n",
    "            R_heel_ref= distance_between_landmarks(left_heel_cord, center)  \n",
    "            L_heel_ref= distance_between_landmarks(right_heel_cord,center)\n",
    "            R_hand_ref= distance_between_landmarks(right_hand_cord, center)\n",
    "            L_hand_ref= distance_between_landmarks(left_hand_cord, center)\n",
    "            \n",
    "            #get view\n",
    "            if all(landmark.visibility > landmark_visibility_threshold for landmark in results.pose_landmarks.landmark):\n",
    "                viewpoint =infer_viewpoint(results.pose_landmarks)\n",
    "\n",
    "                #Prepare Inference dataset for prediction\n",
    "                cols=['view','heel_dist','wrist_dist','knee_dist','right_arm_angle1','left_arm_angle1','right_arm_angle2','left_arm_angle2','right_leg_angle1','left_leg_angle1','right_leg_angle2','left_leg_angle2','Height','R_hand_ref','L_hand_ref', 'R_heel_ref','L_heel_ref']                \n",
    "                l1=[viewpoint,heel_dist,wrist_dist,knee_dist,right_arm_angle1,left_arm_angle1,right_arm_angle2,left_arm_angle2,right_leg_angle1,left_leg_angle1,right_leg_angle2,left_leg_angle2,height,R_hand_ref,L_hand_ref,R_heel_ref,L_heel_ref]            \n",
    "                row =l1 \n",
    "                X = pd.DataFrame([row])\n",
    "                X.columns = cols                \n",
    "                if X['view'][0] == \"Front\":\n",
    "                    X[\"Front\"] = 1\n",
    "                    X[\"Side\"] = 0\n",
    "                    first_column1 = X.pop('Front')\n",
    "                    first_column2 = X.pop('Side')\n",
    "                    X.insert(1, 'Front', first_column1)\n",
    "                    X.insert(2, 'Side', first_column2)\n",
    "                    X=X.drop('view', axis=1)\n",
    "                    X.columns = X.columns.astype(str)\n",
    "                elif X['view'][0]==\"Side\":\n",
    "                    X[\"Front\"] = 0\n",
    "                    X[\"Side\"] = 1\n",
    "                    first_column1 = X.pop('Front')\n",
    "                    first_column2 = X.pop('Side')\n",
    "                    X.insert(1, 'Front', first_column1)\n",
    "                    X.insert(2, 'Side', first_column2)\n",
    "                    X=X.drop('view', axis=1)                \n",
    "                else:\n",
    "                    print(\"No view in DF\")\n",
    "\n",
    "                #Make prediction\n",
    "                body_language_class = model.predict(X)[0]                \n",
    "                body_language_prob = model.predict_proba(X)[0]\n",
    "                a= round(body_language_prob[np.argmax(body_language_prob)],2)                \n",
    "                \n",
    "                # Process detections ONLY if there are any\n",
    "                if results_1[0].boxes is not None and len(results_1[0].boxes.xyxy) > 0: #Check if detections are empty\n",
    "                    boxes = results_1[0].boxes.xyxy.int().tolist()  # Bounding boxes in xyxy format\n",
    "                    confidences = results_1[0].boxes.conf.tolist()\n",
    "                    class_ids = results_1[0].boxes.cls.int().tolist()                    \n",
    "                    class_id= list((results_1[0].boxes.cls))                   \n",
    "                    conf= list((results_1[0].boxes.conf))                    \n",
    "                    predicted_class=[]\n",
    "                    if not len(class_id) == 0:\n",
    "                        for i in class_id:\n",
    "                            i= int(i)\n",
    "                            predicted_class.append(classes[i])\n",
    "                    else:\n",
    "                        print(\"no class id\")\n",
    "\n",
    "                    cord_list= list((results_1[0].boxes.xyxyn))\n",
    "                    result= results_1[0].boxes.xyxyn[0].cpu().numpy()\n",
    "                    x1, y1, x2, y2 = result[0],result[1],result[2],result[3]\n",
    "                    \n",
    "\n",
    "                    for i,j,k in zip(cord_list, range(len(classes)), range(len(conf))):\n",
    "                        frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "                        # Convert normalized coordinates to pixel coordinates\n",
    "                        x1= i[0]*frame_width\n",
    "                        y1=i[1]*frame_height\n",
    "                        x2=i[2]*frame_width\n",
    "                        y2=i[3]*frame_height                        \n",
    "                        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])# Ensure coordinates are integers\n",
    "                        \n",
    "                        # Ensure coordinates are within image boundaries\n",
    "                        x1 = max(0, x1)\n",
    "                        y1 = max(0, y1)\n",
    "                        x2 = min(frame.shape[1], x2)\n",
    "                        y2 = min(frame.shape[0], y2)\n",
    "                        name= predicted_class[j]\n",
    "                        confidence= float(conf[k])\n",
    "                        person= body_language_class\n",
    "                        print(name,person)\n",
    "                        if confidence >conf_thresh or round(body_language_prob[np.argmax(body_language_prob)],2)> conf_thresh2 :                         \n",
    "                            \n",
    "                            if round(body_language_prob[np.argmax(body_language_prob)],2)> conf_thresh2:\n",
    "                                if not person == name:                               \n",
    "                                    cv2.rectangle(frame, (left_shoulder[0]-60, left_shoulder[1]-80), (right_heel[0]+60, right_heel[1]), (0, 255, 0), 2) #Draws a normal rectangle\n",
    "                                    cv2.putText(frame, person.split(' ')[0]\n",
    "                                                    , (left_shoulder[0]-60,(left_shoulder[1]-80)-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                                    cv2.putText(frame, viewpoint.split(' ')[0]\n",
    "                                                    , (220,40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)                                \n",
    "                                \n",
    "                                    cv2.putText(frame, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                                                , ((left_shoulder[0]-60)+60,(left_shoulder[1]-80)-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                                else: \n",
    "                                    text_bg_color = (0, 128, 0)  # Same as the bounding box color\n",
    "                                    text_color = (255, 255, 255)  # White text color\n",
    "                                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                                    font_scale = 0.5\n",
    "                                    font_thickness = 1\n",
    "                                    (person_width, person_height), _ = cv2.getTextSize(person.split(' ')[0], font, font_scale, font_thickness)\n",
    "                                    person_text_position = (x1,y1-5)\n",
    "                                    viewpoint_text_position = (220, 40)\n",
    "                                    probability_text_position = (x1+65,y1-5)\n",
    "\n",
    "                                    # Calculate the size of the text to draw the background rectangle accordingly\n",
    "                                    (person_width, person_height), _ = cv2.getTextSize(name.split(' ')[0], font, font_scale, font_thickness)\n",
    "                                    (viewpoint_width, viewpoint_height), _ = cv2.getTextSize(viewpoint.split(' ')[0], font, font_scale, font_thickness)\n",
    "                                    (probability_width, probability_height), _ = cv2.getTextSize(str(round(confidence, 2)), font, font_scale, font_thickness)\n",
    "\n",
    "                                    # Draw a filled rectangle behind the text to enhance visibility\n",
    "                                    cv2.rectangle(frame, (person_text_position[0] - 5, person_text_position[1] - person_height - 5), \n",
    "                                                (person_text_position[0] + person_width + 5, person_text_position[1] + 5), text_bg_color, -1)\n",
    "                                    cv2.rectangle(frame, (viewpoint_text_position[0] - 5, viewpoint_text_position[1] - viewpoint_height - 5), \n",
    "                                                (viewpoint_text_position[0] + viewpoint_width + 5, viewpoint_text_position[1] + 5), text_bg_color, -1)\n",
    "                                    cv2.rectangle(frame, (probability_text_position[0] - 5, probability_text_position[1] - probability_height - 5), \n",
    "                                                (probability_text_position[0] + probability_width + 5, probability_text_position[1] + 5), text_bg_color, -1)\n",
    "                                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)                               \n",
    "                                    cv2.putText(frame, name.split(' ')[0]\n",
    "                                                    , (x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)                                \n",
    "                                    cv2.putText(frame, str(round(confidence,2))\n",
    "                                                , (x1+65,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "                            elif confidence >conf_thresh:\n",
    "                                text_bg_color = (0, 128, 0)  # Same as the bounding box color\n",
    "                                text_color = (255, 255, 255)  # White text color\n",
    "                                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                                font_scale = 0.5\n",
    "                                font_thickness = 1\n",
    "                                (person_width, person_height), _ = cv2.getTextSize(person.split(' ')[0], font, font_scale, font_thickness)\n",
    "                                person_text_position = (x1,y1-5)\n",
    "                                viewpoint_text_position = (220, 40)\n",
    "                                probability_text_position = (x1+65,y1-5)\n",
    "\n",
    "                                # Calculate the size of the text to draw the background rectangle accordingly\n",
    "                                (person_width, person_height), _ = cv2.getTextSize(name.split(' ')[0], font, font_scale, font_thickness)\n",
    "                                (viewpoint_width, viewpoint_height), _ = cv2.getTextSize(viewpoint.split(' ')[0], font, font_scale, font_thickness)\n",
    "                                (probability_width, probability_height), _ = cv2.getTextSize(str(round(confidence, 2)), font, font_scale, font_thickness)\n",
    "\n",
    "                                # Draw a filled rectangle behind the text to enhance visibility\n",
    "                                cv2.rectangle(frame, (person_text_position[0] - 5, person_text_position[1] - person_height - 5), \n",
    "                                            (person_text_position[0] + person_width + 5, person_text_position[1] + 5), text_bg_color, -1)\n",
    "                                cv2.rectangle(frame, (viewpoint_text_position[0] - 5, viewpoint_text_position[1] - viewpoint_height - 5), \n",
    "                                            (viewpoint_text_position[0] + viewpoint_width + 5, viewpoint_text_position[1] + 5), text_bg_color, -1)\n",
    "                                cv2.rectangle(frame, (probability_text_position[0] - 5, probability_text_position[1] - probability_height - 5), \n",
    "                                            (probability_text_position[0] + probability_width + 5, probability_text_position[1] + 5), text_bg_color, -1)\n",
    "                                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) #Draws a normal rectangle                               \n",
    "                                cv2.putText(frame, name.split(' ')[0]\n",
    "                                                , (x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)                                \n",
    "                                cv2.putText(frame, str(round(confidence,2))\n",
    "                                            , (x1+65,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                            else: \n",
    "                                print(\"low confidence\")\n",
    "                        else: \n",
    "                            print(\"No confidence\")    \n",
    "            else:\n",
    "                print(\"no viewpoint due to insufficienct landmarks\")\n",
    "                # Process detections ONLY if there are any\n",
    "                if results_1[0].boxes is not None and len(results_1[0].boxes.xyxy) > 0: #Check if detections are empty\n",
    "                    boxes = results_1[0].boxes.xyxy.int().tolist()  # Bounding boxes in xyxy format\n",
    "                    confidences = results_1[0].boxes.conf.tolist()\n",
    "                    class_ids = results_1[0].boxes.cls.int().tolist()\n",
    "\n",
    "                    # print(results[0].boxes.cls)\n",
    "                    class_id= list((results_1[0].boxes.cls))\n",
    "                    conf= list((results_1[0].boxes.conf))\n",
    "                    predicted_class=[]\n",
    "                    if not len(class_id) == 0:\n",
    "                        for i in class_id:\n",
    "                            i= int(i)\n",
    "                            predicted_class.append(classes[i])\n",
    "                    else:\n",
    "                        print(\"no class id\")\n",
    "                    cord_list= list((results_1[0].boxes.xyxyn))\n",
    "                    result= results_1[0].boxes.xyxyn[0].cpu().numpy()\n",
    "                    x1, y1, x2, y2 = result[0],result[1],result[2],result[3]                 \n",
    "\n",
    "                    for i,j,k in zip(cord_list, range(len(classes)), range(len(conf))):\n",
    "                        frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "                        # Convert normalized coordinates to pixel coordinates\n",
    "                        x1= i[0]*frame_width\n",
    "                        y1=i[1]*frame_height\n",
    "                        x2=i[2]*frame_width\n",
    "                        y2=i[3]*frame_height            \n",
    "                        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])# Ensure coordinates are integers\n",
    "\n",
    "                        # Ensure coordinates are within image boundaries\n",
    "                        x1 = max(0, x1)\n",
    "                        y1 = max(0, y1)\n",
    "                        x2 = min(frame.shape[1], x2)\n",
    "                        y2 = min(frame.shape[0], y2)\n",
    "                        name= predicted_class[j]                                           \n",
    "                        confidence= float(conf[k])\n",
    "                        if  confidence > conf_thresh:\n",
    "                            text_bg_color = (0, 128, 0)  # Same as the bounding box color\n",
    "                            text_color = (255, 255, 255)  # White text color\n",
    "                            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                            font_scale = 0.5\n",
    "                            font_thickness = 1\n",
    "                            (person_width, person_height), _ = cv2.getTextSize(name.split(' ')[0], font, font_scale, font_thickness)\n",
    "                            person_text_position = (x1,y1-5)\n",
    "                            viewpoint_text_position = (220, 40)\n",
    "                            probability_text_position = (x1+65,y1-5)\n",
    "\n",
    "                            # Calculate the size of the text to draw the background rectangle accordingly\n",
    "                            (person_width, person_height), _ = cv2.getTextSize(name.split(' ')[0], font, font_scale, font_thickness)                            \n",
    "                            (probability_width, probability_height), _ = cv2.getTextSize(str(round(confidence, 2)), font, font_scale, font_thickness)\n",
    "\n",
    "                            # Draw a filled rectangle behind the text to enhance visibility\n",
    "                            cv2.rectangle(frame, (person_text_position[0] - 5, person_text_position[1] - person_height - 5), \n",
    "                                        (person_text_position[0] + person_width + 5, person_text_position[1] + 5), text_bg_color, -1)\n",
    "                            cv2.rectangle(frame, (probability_text_position[0] - 5, probability_text_position[1] - probability_height - 5), \n",
    "                                        (probability_text_position[0] + probability_width + 5, probability_text_position[1] + 5), text_bg_color, -1)\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) #Draws a normal rectangle                               \n",
    "                            cv2.putText(frame, name.split(' ')[0]\n",
    "                                            , (x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)                                \n",
    "                            cv2.putText(frame, str(round(confidence,2))\n",
    "                                        , (x1+65,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                        else:\n",
    "                            print(\"low confidence level_2\")\n",
    "                else:\n",
    "                    print(\"no facial detection\")        \n",
    "                    \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "         # Process detections ONLY if there are any\n",
    "        elif results_1[0].boxes is not None and len(results_1[0].boxes.xyxy) > 0: #Check if detections are empty\n",
    "            boxes = results_1[0].boxes.xyxy.int().tolist()  # Bounding boxes in xyxy format\n",
    "            confidences = results_1[0].boxes.conf.tolist()\n",
    "            class_ids = results_1[0].boxes.cls.int().tolist()            \n",
    "            class_id= list((results_1[0].boxes.cls))\n",
    "            conf= list((results_1[0].boxes.conf))\n",
    "            predicted_class=[]\n",
    "            if not len(class_id) == 0:\n",
    "                for i in class_id:\n",
    "                    i= int(i)\n",
    "                    predicted_class.append(classes[i])\n",
    "            else:\n",
    "                print(\"no class id\")\n",
    "            cord_list= list((results_1[0].boxes.xyxyn))\n",
    "            result= results_1[0].boxes.xyxyn[0].cpu().numpy()\n",
    "            x1, y1, x2, y2 = result[0],result[1],result[2],result[3]          \n",
    "\n",
    "            for i,j,k in zip(cord_list, range(len(classes)), range(len(conf))):\n",
    "                frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "                # Convert normalized coordinates to pixel coordinates\n",
    "                x1= i[0]*frame_width\n",
    "                y1=i[1]*frame_height\n",
    "                x2=i[2]*frame_width\n",
    "                y2=i[3]*frame_height                \n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])# Ensure coordinates are integers\n",
    "\n",
    "                # Ensure coordinates are within image boundaries\n",
    "                x1 = max(0, x1)\n",
    "                y1 = max(0, y1)\n",
    "                x2 = min(frame.shape[1], x2)\n",
    "                y2 = min(frame.shape[0], y2)\n",
    "                name= predicted_class[j]                                           \n",
    "                confidence= float(conf[k])\n",
    "                if  confidence > conf_thresh:\n",
    "                    text_bg_color = (0, 128, 0)  # Same as the bounding box color\n",
    "                    text_color = (255, 255, 255)  # White text color\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    font_scale = 0.5\n",
    "                    font_thickness = 1\n",
    "                    (person_width, person_height), _ = cv2.getTextSize(name.split(' ')[0], font, font_scale, font_thickness)\n",
    "                    person_text_position = (x1,y1-5)\n",
    "                    viewpoint_text_position = (220, 40)\n",
    "                    probability_text_position = (x1+65,y1-5)\n",
    "\n",
    "                    # Calculate the size of the text to draw the background rectangle accordingly\n",
    "                    (person_width, person_height), _ = cv2.getTextSize(name.split(' ')[0], font, font_scale, font_thickness)\n",
    "                    (viewpoint_width, viewpoint_height), _ = cv2.getTextSize(viewpoint.split(' ')[0], font, font_scale, font_thickness)\n",
    "                    (probability_width, probability_height), _ = cv2.getTextSize(str(round(confidence, 2)), font, font_scale, font_thickness)\n",
    "\n",
    "                    # Draw a filled rectangle behind the text to enhance visibility\n",
    "                    cv2.rectangle(frame, (person_text_position[0] - 5, person_text_position[1] - person_height - 5), \n",
    "                                (person_text_position[0] + person_width + 5, person_text_position[1] + 5), text_bg_color, -1)\n",
    "                    cv2.rectangle(frame, (viewpoint_text_position[0] - 5, viewpoint_text_position[1] - viewpoint_height - 5), \n",
    "                                (viewpoint_text_position[0] + viewpoint_width + 5, viewpoint_text_position[1] + 5), text_bg_color, -1)\n",
    "                    cv2.rectangle(frame, (probability_text_position[0] - 5, probability_text_position[1] - probability_height - 5), \n",
    "                                (probability_text_position[0] + probability_width + 5, probability_text_position[1] + 5), text_bg_color, -1)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) #Draws a normal rectangle                               \n",
    "                    cv2.putText(frame, name.split(' ')[0]\n",
    "                                    , (x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)                                \n",
    "                    cv2.putText(frame, str(round(confidence,2))\n",
    "                                , (x1+65,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                else:\n",
    "                    print(\"low confidence level_3\")\n",
    "            else:\n",
    "                print(\"no facial detection\")     \n",
    "        \n",
    "        # Display the annotated frame\n",
    "        cv2.imshow('YOLOv8', frame)\n",
    "        \n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break             \n",
    "        else: \n",
    "            print(\"no detections available\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
